{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartat B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import sklearn.linear_model\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "# Visualitzarem 4 decimals per mostra\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "\n",
    "dataset0 = pd.read_csv(\"0.csv\", header=0, delimiter=',', decimal=\".\", names=[\"1.1\",\"1.2\",\"1.3\",\"1.4\",\"1.5\",\"1.6\",\"1.7\", \"1.8\", \"2.1\",\"2.2\",\"2.3\",\"2.4\",\"2.5\",\"2.6\",\"2.7\", \"2.8\",\"3.1\",\"3.2\",\"3.3\",\"3.4\",\"3.5\",\"3.6\",\"3.7\", \"3.8\",\"4.1\",\"4.2\",\"4.3\",\"4.4\",\"4.5\",\"4.6\",\"4.7\", \"4.8\",\"5.1\",\"5.2\",\"5.3\",\"5.4\",\"5.5\",\"5.6\",\"5.7\", \"5.8\",\"6.1\",\"6.2\",\"6.3\",\"6.4\",\"6.5\",\"6.6\",\"6.7\", \"6.8\",\"7.1\",\"7.2\",\"7.3\",\"7.4\",\"7.5\",\"7.6\",\"7.7\", \"7.8\",\"8.1\",\"8.2\",\"8.3\",\"8.4\",\"8.5\",\"8.6\",\"8.7\", \"8.8\", \"GESTO\"])\n",
    "dataset1 = pd.read_csv(\"1.csv\", header=0, delimiter=',', decimal=\".\", names=[\"1.1\",\"1.2\",\"1.3\",\"1.4\",\"1.5\",\"1.6\",\"1.7\", \"1.8\", \"2.1\",\"2.2\",\"2.3\",\"2.4\",\"2.5\",\"2.6\",\"2.7\", \"2.8\",\"3.1\",\"3.2\",\"3.3\",\"3.4\",\"3.5\",\"3.6\",\"3.7\", \"3.8\",\"4.1\",\"4.2\",\"4.3\",\"4.4\",\"4.5\",\"4.6\",\"4.7\", \"4.8\",\"5.1\",\"5.2\",\"5.3\",\"5.4\",\"5.5\",\"5.6\",\"5.7\", \"5.8\",\"6.1\",\"6.2\",\"6.3\",\"6.4\",\"6.5\",\"6.6\",\"6.7\", \"6.8\",\"7.1\",\"7.2\",\"7.3\",\"7.4\",\"7.5\",\"7.6\",\"7.7\", \"7.8\",\"8.1\",\"8.2\",\"8.3\",\"8.4\",\"8.5\",\"8.6\",\"8.7\", \"8.8\", \"GESTO\"])\n",
    "dataset2 = pd.read_csv(\"2.csv\", header=0, delimiter=',', decimal=\".\", names=[\"1.1\",\"1.2\",\"1.3\",\"1.4\",\"1.5\",\"1.6\",\"1.7\", \"1.8\", \"2.1\",\"2.2\",\"2.3\",\"2.4\",\"2.5\",\"2.6\",\"2.7\", \"2.8\",\"3.1\",\"3.2\",\"3.3\",\"3.4\",\"3.5\",\"3.6\",\"3.7\", \"3.8\",\"4.1\",\"4.2\",\"4.3\",\"4.4\",\"4.5\",\"4.6\",\"4.7\", \"4.8\",\"5.1\",\"5.2\",\"5.3\",\"5.4\",\"5.5\",\"5.6\",\"5.7\", \"5.8\",\"6.1\",\"6.2\",\"6.3\",\"6.4\",\"6.5\",\"6.6\",\"6.7\", \"6.8\",\"7.1\",\"7.2\",\"7.3\",\"7.4\",\"7.5\",\"7.6\",\"7.7\", \"7.8\",\"8.1\",\"8.2\",\"8.3\",\"8.4\",\"8.5\",\"8.6\",\"8.7\", \"8.8\", \"GESTO\"])\n",
    "dataset3 = pd.read_csv(\"3.csv\", header=0, delimiter=',', decimal=\".\", names=[\"1.1\",\"1.2\",\"1.3\",\"1.4\",\"1.5\",\"1.6\",\"1.7\", \"1.8\", \"2.1\",\"2.2\",\"2.3\",\"2.4\",\"2.5\",\"2.6\",\"2.7\", \"2.8\",\"3.1\",\"3.2\",\"3.3\",\"3.4\",\"3.5\",\"3.6\",\"3.7\", \"3.8\",\"4.1\",\"4.2\",\"4.3\",\"4.4\",\"4.5\",\"4.6\",\"4.7\", \"4.8\",\"5.1\",\"5.2\",\"5.3\",\"5.4\",\"5.5\",\"5.6\",\"5.7\", \"5.8\",\"6.1\",\"6.2\",\"6.3\",\"6.4\",\"6.5\",\"6.6\",\"6.7\", \"6.8\",\"7.1\",\"7.2\",\"7.3\",\"7.4\",\"7.5\",\"7.6\",\"7.7\", \"7.8\",\"8.1\",\"8.2\",\"8.3\",\"8.4\",\"8.5\",\"8.6\",\"8.7\", \"8.8\", \"GESTO\"])\n",
    "\n",
    "dataset = pd.concat([dataset0, dataset1])\n",
    "dataset = pd.concat([dataset, dataset2])\n",
    "dataset = pd.concat([dataset, dataset3])\n",
    "dataset = dataset.reset_index()\n",
    "\n",
    "data = dataset.values\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "print(\"Dimensionalitat de la BBDD:\", dataset.shape)\n",
    "print(\"Dimensionalitat de les entrades X\", x.shape)\n",
    "print(\"Dimensionalitat de l'atribut Y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = dataset[[\"1.1\",\"1.2\",\"1.3\",\"1.4\",\"1.5\",\"1.6\",\"1.7\", \"1.8\", \"GESTO\"]].copy()\n",
    "dataset2 = dataset[[\"2.1\",\"2.2\",\"2.3\",\"2.4\",\"2.5\",\"2.6\",\"2.7\", \"2.8\", \"GESTO\"]].copy()\n",
    "dataset3 = dataset[[\"3.1\",\"3.2\",\"3.3\",\"3.4\",\"3.5\",\"3.6\",\"3.7\", \"3.8\", \"GESTO\"]].copy()\n",
    "dataset4 = dataset[[\"4.1\",\"4.2\",\"4.3\",\"4.4\",\"4.5\",\"4.6\",\"4.7\", \"4.8\", \"GESTO\"]].copy()\n",
    "dataset5 = dataset[[\"5.1\",\"5.2\",\"5.3\",\"5.4\",\"5.5\",\"5.6\",\"5.7\", \"5.8\", \"GESTO\"]].copy()\n",
    "dataset6 = dataset[[\"6.1\",\"6.2\",\"6.3\",\"6.4\",\"6.5\",\"6.6\",\"6.7\", \"6.8\", \"GESTO\"]].copy()\n",
    "dataset7 = dataset[[\"7.1\",\"7.2\",\"7.3\",\"7.4\",\"7.5\",\"7.6\",\"7.7\", \"7.8\", \"GESTO\"]].copy()\n",
    "dataset8 = dataset[[\"8.1\",\"8.2\",\"8.3\",\"8.4\",\"8.5\",\"8.6\",\"8.7\", \"8.8\", \"GESTO\"]].copy()\n",
    "co1 = dataset1.corr()\n",
    "co2 = dataset2.corr()\n",
    "co3 = dataset3.corr()\n",
    "co4 = dataset4.corr()\n",
    "co5 = dataset5.corr()\n",
    "co6 = dataset6.corr()\n",
    "co7 = dataset7.corr()\n",
    "co8 = dataset8.corr()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ax1 = sns.heatmap(co1, annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = sns.heatmap(co2, annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3 = sns.heatmap(co3, annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax4 = sns.heatmap(co4, annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax5 = sns.heatmap(co5, annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax6 = sns.heatmap(co6, annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax7 = sns.heatmap(co7, annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax8 = sns.heatmap(co8, annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogrames i pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.hist(figsize=(12, 12))\n",
    "rel1 = sns.pairplot(dataset1, hue='GESTO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.hist(figsize=(12, 12))\n",
    "rel2 = sns.pairplot(dataset2, hue='GESTO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3.hist(figsize=(12, 12))\n",
    "rel3 = sns.pairplot(dataset3, hue='GESTO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4.hist(figsize=(12, 12))\n",
    "rel4 = sns.pairplot(dataset4, hue='GESTO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset5.hist(figsize=(12, 12))\n",
    "rel5 = sns.pairplot(dataset5, hue='GESTO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset6.hist(figsize=(12, 12))\n",
    "rel6 = sns.pairplot(dataset6, hue='GESTO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset7.hist(figsize=(12, 12))\n",
    "rel7 = sns.pairplot(dataset7, hue='GESTO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset8.hist(figsize=(12, 12))\n",
    "rel8 = sns.pairplot(dataset8, hue='GESTO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing (normalization, outlier removal, feature selection..) \n",
    "## + 4. Crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declarem tots els tipus de normalitzaci√≥ que volem provar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = x.astype(float)\n",
    "y = y.astype(float)\n",
    "minmax = sklearn.preprocessing.MinMaxScaler()\n",
    "#x_minmax = minmax.fit_transform(x)\n",
    "\n",
    "standard = sklearn.preprocessing.StandardScaler()\n",
    "#x_standard = standard.fit_transform(x)\n",
    "\n",
    "robust = sklearn.preprocessing.RobustScaler()\n",
    "#x_robust = robust.fit_transform(x)\n",
    "\n",
    "yeoJohnson = sklearn.preprocessing.PowerTransformer()\n",
    "#x_yeoJohnson = yeoJohnson.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Els provem tots amb stratified k-fold i amb logistic regression, per veure els resultats de cadasc√∫n i escollir un tipus de normalitzacio a partir d'aquests resultats. (Encara que crossvalidation sigui a l'apartat 4, hem decidit fer-ho a aquest punt ja que considerem que per normalitzar les dades ja necessitem tenir les dades separades en train i test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticReg = sklearn.linear_model.LogisticRegression(max_iter=1000)\n",
    "\n",
    "skf = sklearn.model_selection.StratifiedKFold(n_splits=5, shuffle=True)\n",
    "accuracy_sense = []\n",
    "accuracy_minmax = []\n",
    "accuracy_standard = []\n",
    "accuracy_robust = []\n",
    "accuracy_yeoJohnson = []\n",
    "\n",
    "\n",
    "#DE MOMENTO LAS COMENTO PORQ CON ESAS DOS ME DICE QUE LO TENGO QUE ESTANDARIZAR PORQ SE PASAN DEL NUMERO MAXIMO DE ITERACIONES\n",
    "\n",
    "'''\n",
    "#Sense normalitzaci√≥\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    logisticReg.fit(x_train, y_train)\n",
    "    accuracy_sense.append(logisticReg.score(x_test, y_test))\n",
    "\n",
    "print('\\nSense Scaler:')\n",
    "print('List of possible accuracy:', accuracy_sense)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(accuracy_sense)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(accuracy_sense)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(accuracy_sense)*100, '%')\n",
    "    \n",
    "\n",
    "#MinMax\n",
    "\n",
    "for train_index, test_index in skf.split(x_minmax, y):\n",
    "    x_train, x_test = x_minmax[train_index], x_minmax[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    logisticReg.fit(x_train, y_train)\n",
    "    accuracy_minmax.append(logisticReg.score(x_test, y_test))\n",
    "\n",
    "print('\\nMinMax Scaler')\n",
    "print('List of possible accuracy:', accuracy_minmax)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(accuracy_minmax)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(accuracy_minmax)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(accuracy_minmax)*100, '%')\n",
    "'''\n",
    "\n",
    "#Standard_Scaler\n",
    "\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    \n",
    "    x_train = standard.fit_transform(x_train)\n",
    "    x_test = standard.transform(x_test)\n",
    "    \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    logisticReg.fit(x_train, y_train)\n",
    "    accuracy_standard.append(logisticReg.score(x_test, y_test))\n",
    "\n",
    "print('\\nStandard Scaler:')\n",
    "print('List of possible accuracy:', accuracy_standard)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(accuracy_standard)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(accuracy_standard)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(accuracy_standard)*100, '%')\n",
    "\n",
    "#Robust_Scaler\n",
    "\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    \n",
    "    x_train = robust.fit_transform(x_train)\n",
    "    x_test = robust.transform(x_test)\n",
    "    \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    logisticReg.fit(x_train, y_train)\n",
    "    accuracy_robust.append(logisticReg.score(x_test, y_test))\n",
    "\n",
    "print('\\nRobust Scaler:')\n",
    "print('List of possible accuracy:', accuracy_robust)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(accuracy_robust)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(accuracy_robust)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(accuracy_robust)*100, '%')\n",
    "\n",
    "#Yeo-Johson\n",
    "\n",
    "for train_index, test_index in skf.split(x, y):   \n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    \n",
    "    x_train = yeoJohnson.fit_transform(x_train)\n",
    "    x_test = yeoJohnson.transform(x_test)\n",
    "    \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    logisticReg.fit(x_train, y_train)\n",
    "    accuracy_yeoJohnson.append(logisticReg.score(x_test, y_test))\n",
    "\n",
    "print('\\nYeo-Johnson Scaler:')\n",
    "print('List of possible accuracy:', accuracy_yeoJohnson)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(accuracy_yeoJohnson)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(accuracy_yeoJohnson)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(accuracy_yeoJohnson)*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El scaler que ens ha donat millor resultat es el Yeo-Johnson, per lo tant √©s el que utilitzarem d'aqui endavant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isoForest = IsolationForest()\n",
    "outliers = isoForest.fit_predict(x_train)\n",
    "\n",
    "print(f\"outliers = {outliers}\")\n",
    "\n",
    "x_trainOut = x_train[outliers == 1]\n",
    "y_trainOut = y_train[outliers == 1]\n",
    "print(x_train.shape)\n",
    "print(x_trainOut.shape)\n",
    "\n",
    "x_train = x_trainOut\n",
    "y_train = y_trainOut\n",
    "#ENCONTRAR FORMA DE VISUALIZAR LA DIFERENCIA ENTRE CUANDO TENIA OUTLIERS I CUANDO NO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.svm\n",
    "\n",
    "\n",
    "\n",
    "#classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "classifier = sklearn.linear_model.LogisticRegression(max_iter=1000)\n",
    "#classifier = sklearn.svm.SVC()\n",
    "\n",
    "\n",
    "accs, r2s = [], []\n",
    "for i in range(1, x_train.shape[1]):\n",
    "    pca = PCA(n_components=i)\n",
    "    x_train_transformed = pca.fit_transform(x_train)\n",
    "    x_test_transformed = pca.transform(x_test)\n",
    "\n",
    "    \n",
    "    classifier.fit(x_train_transformed, y_train)\n",
    "    preds = classifier.predict(x_test_transformed)\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    \n",
    "    print(f\"PCA_{i} - Accuracy: {acc:.3f};\")\n",
    "    \n",
    "    accs.append(acc)\n",
    "    #r2s.append(r2)\n",
    "    \n",
    "plt.plot(accs, label='accuracy')\n",
    "plt.plot(r2s, label='r2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "classifier = sklearn.linear_model.LogisticRegression(max_iter=1000)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "x_trainPoly = poly.fit_transform(x_train)\n",
    "x_testPoly = poly.fit_transform(x_test)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "preds = classifier.predict(x_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "print(\"Normal:\")\n",
    "print(f\"Accuracy: {acc:.3f};\")\n",
    "\n",
    "\n",
    "classifier.fit(x_trainPoly, y_train)\n",
    "preds = classifier.predict(x_testPoly)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "print(\"Polynomial Features:\")\n",
    "print(f\"Accuracy: {acc:.3f};\")\n",
    "print(\"x_train shape: \" + str(x_train.shape))\n",
    "print(\"x_train(Polynomial Features) shape: \" + str(x_trainPoly.shape))\n",
    "\n",
    "x_train = x_trainPoly\n",
    "x_test = x_testPoly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com es pot veure, al aplicar Polynomial features ens dona molt millor resultat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tornem a provar el PCA despres d'aplicar el Polynomial features ja que els atributs han passat de 65 a 2211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LO COMENTO PORQ SOLO ES PARA MOSTRAR DATOS Y ASI LO PODEMOS EJECUTAR MAS RAPIDO\n",
    "'''\n",
    "classifier = sklearn.linear_model.LogisticRegression(max_iter=1000)\n",
    "#classifier = sklearn.svm.SVC()\n",
    "print(x_train.shape)\n",
    "\n",
    "accs, r2s = [], []\n",
    "for i in range(1, x_train.shape[1], 200):\n",
    "    pca = PCA(n_components=i)\n",
    "    x_train_transformed = pca.fit_transform(x_train)\n",
    "    x_test_transformed = pca.transform(x_test)\n",
    "\n",
    "    \n",
    "    classifier.fit(x_train_transformed, y_train)\n",
    "    preds = classifier.predict(x_test_transformed)\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    \n",
    "    print(f\"PCA_{i} - Accuracy: {acc:.3f};\")\n",
    "    \n",
    "    accs.append(acc)\n",
    "    \n",
    "plt.plot(accs, label='accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Selection + 5. Metric Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probarem els models: Regressi√≥ Log√≠stica, SVC, Linear SVC, SVC(rbf), SVC(Polynomial), Nearest Neighbors, i Perceptron. I per a mesurar aquests models utilitzarem l'accuracy score i el F1 score(ja que l'average precision score no funciona amb problema multiclass)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecci√≥ de Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "logRegr = sklearn.linear_model.LogisticRegression(max_iter=1000)\n",
    "svc = SVC(kernel=\"linear\") \n",
    "linearsvc = LinearSVC(max_iter=1000)\n",
    "svcRBF = SVC(kernel=\"rbf\")\n",
    "svcPoly = SVC(kernel=\"poly\")\n",
    "nn = KNeighborsClassifier()\n",
    "percep = Perceptron()\n",
    "\n",
    "logRegr.fit(x_train, y_train)\n",
    "preds = logRegr.predict(x_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds, average=\"micro\")\n",
    "prec = precision_score(y_test, preds, average=\"micro\")\n",
    "rec = recall_score(y_test, preds, average=\"micro\")\n",
    "print(f\"Logistic Regression: Accuracy = {acc:.3f}; f1_score = {f1:.3f}; Precision = {prec:.3f}; Recall = {rec:.3f};\")\n",
    "print(\"\")\n",
    "\n",
    "svc.fit(x_train, y_train)\n",
    "preds = svc.predict(x_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds, average=\"micro\")\n",
    "prec = precision_score(y_test, preds, average=\"micro\")\n",
    "rec = recall_score(y_test, preds, average=\"micro\")\n",
    "print(f\"SVC: Accuracy = {acc:.3f}; f1_score = {f1:.3f}; Precision = {prec:.3f}; Recall = {rec:.3f};\")\n",
    "print(\"\")\n",
    "\n",
    "linearsvc.fit(x_train, y_train)\n",
    "preds = linearsvc.predict(x_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds, average=\"micro\")\n",
    "prec = precision_score(y_test, preds, average=\"micro\")\n",
    "rec = recall_score(y_test, preds, average=\"micro\")\n",
    "print(f\"linearSVC: Accuracy = {acc:.3f}; f1_score = {f1:.3f}; Precision = {prec:.3f}; Recall = {rec:.3f};\")\n",
    "print(\"\")\n",
    "\n",
    "svcRBF.fit(x_train, y_train)\n",
    "preds = svcRBF.predict(x_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds, average=\"micro\")\n",
    "prec = precision_score(y_test, preds, average=\"micro\")\n",
    "rec = recall_score(y_test, preds, average=\"micro\")\n",
    "print(f\"SVC(rbf): Accuracy = {acc:.3f}; f1_score = {f1:.3f}; Precision = {prec:.3f}; Recall = {rec:.3f};\")\n",
    "print(\"\")\n",
    "\n",
    "svcPoly.fit(x_train, y_train)\n",
    "preds = svcPoly.predict(x_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds, average=\"micro\")\n",
    "prec = precision_score(y_test, preds, average=\"micro\")\n",
    "rec = recall_score(y_test, preds, average=\"micro\")\n",
    "print(f\"SVC(Polynomial): Accuracy = {acc:.3f}; f1_score = {f1:.3f}; Precision = {prec:.3f}; Recall = {rec:.3f};\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "knns = dict()\n",
    "for k in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]:\n",
    "    nn = KNeighborsClassifier(n_neighbors=k)\n",
    "    nn.fit(x_train, y_train)\n",
    "    preds = nn.predict(x_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds, average=\"micro\")\n",
    "    prec = precision_score(y_test, preds, average=\"micro\")\n",
    "    rec = recall_score(y_test, preds, average=\"micro\")\n",
    "    print(f\"Nearest Neighbors(k = {k}): Accuracy = {acc:.3f}; f1_score = {f1:.3f}; Precision = {prec:.3f}; Recall = {rec:.3f};\")\n",
    "    print(\"\")\n",
    "    \n",
    "    knns[k] = nn\n",
    "    \n",
    "    \n",
    "percep.fit(x_train, y_train)\n",
    "preds = percep.predict(x_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds, average=\"micro\")\n",
    "prec = precision_score(y_test, preds, average=\"micro\")\n",
    "rec = recall_score(y_test, preds, average=\"micro\")\n",
    "print(f\"Perceptron: Accuracy = {acc:.3f}; f1_score = {f1:.3f}; Precision = {prec:.3f}; Recall = {rec:.3f};\")\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfcs = dict()\n",
    "for t in range(10, 201, 20):\n",
    "    rfc = RandomForestClassifier(n_estimators=t)\n",
    "    rfc.fit(x_train, y_train)\n",
    "    preds = rfc.predict(x_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds, average=\"micro\")\n",
    "    prec = precision_score(y_test, preds, average=\"micro\")\n",
    "    rec = recall_score(y_test, preds, average=\"micro\")\n",
    "    print(f\"Random Forest(trees = {t}): Accuracy = {acc:.3f}; f1_score = {f1:.3f}; Precision = {prec:.3f}; Recall = {rec:.3f};\")\n",
    "    print(\"\")\n",
    "    \n",
    "    rfcs[t] = rfc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per lo tant, el model que ens dona millor accuracy es la regressi√≥ logistica.\n",
    "\n",
    "\n",
    "Ens quedem amb regressi√≥ logistica, SVC, el perceptron y Random Forest(trees = 130)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisi√≥-Recall Curve i ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "def plot_roc_curve(og_classifier, n_classes, x_train, y_train, x_test, y_test, use_proba=False):\n",
    "    clf = OneVsRestClassifier(og_classifier)\n",
    "    if not use_proba:\n",
    "        y_score = clf.fit(x_train, y_train).decision_function(x_test)\n",
    "    else:\n",
    "        y_score = clf.fit(x_train, y_train).predict_proba(x_test)\n",
    "    \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test, y_score[:, i], pos_label=i)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        \n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    pr_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        precisions[i], recalls[i], _ = precision_recall_curve(y_test, y_score[:, i], pos_label=i)\n",
    "        pr_auc[i] = auc(recalls[i], precisions[i])\n",
    "    \n",
    "    # Plot of a ROC curve for a specific class\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "        \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    #plt.plot([0, 1], [0, 1], 'k--')\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        plt.plot(recalls[i], precisions[i], label='Precision-Recall curve (area = %0.2f)' % pr_auc[i])\n",
    "        \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_roc_curve(logRegr, 4, x_train, y_train, x_test, y_test)\n",
    "\n",
    "plot_roc_curve(svc, 4, x_train, y_train, x_test, y_test)\n",
    "\n",
    "plot_roc_curve(percep, 4, x_train, y_train, x_test, y_test)\n",
    "\n",
    "plot_roc_curve(rfcs[130], 4, x_train, y_train, x_test, y_test, use_proba=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e49f01b25252117987057767e4860399151593b17ce2349b8fe42cec150c223d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
